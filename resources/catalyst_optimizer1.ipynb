{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1c8a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57df06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('abc').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57811fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|  first|\n",
      "+---+-------+\n",
      "|  1| Torrey|\n",
      "|  2|  Micah|\n",
      "|  3| Hollis|\n",
      "|  4|  Perry|\n",
      "|  5|Janelle|\n",
      "|  6|Charity|\n",
      "|  7|  Dejah|\n",
      "|  8|  Ellen|\n",
      "|  9|   Sven|\n",
      "| 10|Ryleigh|\n",
      "| 11| Cooper|\n",
      "| 12|Esteban|\n",
      "| 13|Lucinda|\n",
      "| 14| Jarvis|\n",
      "| 15| Jordon|\n",
      "| 16|Marques|\n",
      "| 17|  Edgar|\n",
      "| 18|  Adell|\n",
      "| 19|Madonna|\n",
      "| 20|  Andre|\n",
      "+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.parquet(\"D://TechnoAvengers//DI//Spark_Optimizations//data//parquet//employee.parquet\")\n",
    "df1.createOrReplaceTempView(\"t1\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d1bcc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|             country|\n",
      "+---+--------------------+\n",
      "|  1|         Switzerland|\n",
      "|  2|Democratic People...|\n",
      "|  3|             Tunisia|\n",
      "|  4|                Chad|\n",
      "|  5|           Swaziland|\n",
      "|  6|             Lebanon|\n",
      "|  7|               Egypt|\n",
      "|  8|              Israel|\n",
      "|  9|               Macao|\n",
      "| 10|               Congo|\n",
      "| 11|             Reunion|\n",
      "| 12|          Guadeloupe|\n",
      "| 13|             Lebanon|\n",
      "| 14|               Ghana|\n",
      "| 15|              Serbia|\n",
      "| 16|               Sudan|\n",
      "| 17|   Wallis and Futuna|\n",
      "| 18|        Sierra Leone|\n",
      "| 19|             Namibia|\n",
      "| 20|             Georgia|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.parquet(\"D://TechnoAvengers//DI//Spark_Optimizations//data//parquet//country.parquet\")\n",
    "df2.createOrReplaceTempView(\"t2\")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60bc7308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = spark.sql(\"select * from t1 join t2 on t1.id==t2.id where t2.country!='Switzerland'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bc984c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [*]\n",
      "+- 'Filter NOT ('t2.country = Switzerland)\n",
      "   +- 'Join Inner, ('t1.id = 't2.id)\n",
      "      :- 'UnresolvedRelation [t1]\n",
      "      +- 'UnresolvedRelation [t2]\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "id: bigint, first: string, id: bigint, country: string\n",
      "Project [id#337L, first#338, id#357L, country#358]\n",
      "+- Filter NOT (country#358 = Switzerland)\n",
      "   +- Join Inner, (id#337L = id#357L)\n",
      "      :- SubqueryAlias t1\n",
      "      :  +- Relation[id#337L,first#338] parquet\n",
      "      +- SubqueryAlias t2\n",
      "         +- Relation[id#357L,country#358] parquet\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Join Inner, (id#337L = id#357L)\n",
      ":- Filter isnotnull(id#337L)\n",
      ":  +- Relation[id#337L,first#338] parquet\n",
      "+- Filter ((isnotnull(country#358) AND NOT (country#358 = Switzerland)) AND isnotnull(id#357L))\n",
      "   +- Relation[id#357L,country#358] parquet\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [id#337L], [id#357L], Inner, BuildRight\n",
      ":- *(2) Project [id#337L, first#338]\n",
      ":  +- *(2) Filter isnotnull(id#337L)\n",
      ":     +- *(2) ColumnarToRow\n",
      ":        +- FileScan parquet [id#337L,first#338] Batched: true, DataFilters: [isnotnull(id#337L)], Format: Parquet, Location: InMemoryFileIndex[file:/D:/TechnoAvengers/DI/Spark_Optimizations/data/parquet/employee.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(id)], ReadSchema: struct<id:bigint,first:string>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, true])), [id=#359]\n",
      "   +- *(1) Project [id#357L, country#358]\n",
      "      +- *(1) Filter ((isnotnull(country#358) AND NOT (country#358 = Switzerland)) AND isnotnull(id#357L))\n",
      "         +- *(1) ColumnarToRow\n",
      "            +- FileScan parquet [id#357L,country#358] Batched: true, DataFilters: [isnotnull(country#358), NOT (country#358 = Switzerland), isnotnull(id#357L)], Format: Parquet, Location: InMemoryFileIndex[file:/D:/TechnoAvengers/DI/Spark_Optimizations/data/parquet/country.parquet], PartitionFilters: [], PushedFilters: [IsNotNull(country), Not(EqualTo(country,Switzerland)), IsNotNull(id)], ReadSchema: struct<id:bigint,country:string>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.explain(mode=\"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83213217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "* BroadcastHashJoin Inner BuildRight (10)\n",
      ":- * Project (4)\n",
      ":  +- * Filter (3)\n",
      ":     +- * ColumnarToRow (2)\n",
      ":        +- Scan parquet  (1)\n",
      "+- BroadcastExchange (9)\n",
      "   +- * Project (8)\n",
      "      +- * Filter (7)\n",
      "         +- * ColumnarToRow (6)\n",
      "            +- Scan parquet  (5)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [2]: [id#337L, first#338]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/D:/TechnoAvengers/DI/Spark_Optimizations/data/parquet/employee.parquet]\n",
      "PushedFilters: [IsNotNull(id)]\n",
      "ReadSchema: struct<id:bigint,first:string>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 2]\n",
      "Input [2]: [id#337L, first#338]\n",
      "\n",
      "(3) Filter [codegen id : 2]\n",
      "Input [2]: [id#337L, first#338]\n",
      "Condition : isnotnull(id#337L)\n",
      "\n",
      "(4) Project [codegen id : 2]\n",
      "Output [2]: [id#337L, first#338]\n",
      "Input [2]: [id#337L, first#338]\n",
      "\n",
      "(5) Scan parquet \n",
      "Output [2]: [id#357L, country#358]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/D:/TechnoAvengers/DI/Spark_Optimizations/data/parquet/country.parquet]\n",
      "PushedFilters: [IsNotNull(country), Not(EqualTo(country,Switzerland)), IsNotNull(id)]\n",
      "ReadSchema: struct<id:bigint,country:string>\n",
      "\n",
      "(6) ColumnarToRow [codegen id : 1]\n",
      "Input [2]: [id#357L, country#358]\n",
      "\n",
      "(7) Filter [codegen id : 1]\n",
      "Input [2]: [id#357L, country#358]\n",
      "Condition : ((isnotnull(country#358) AND NOT (country#358 = Switzerland)) AND isnotnull(id#357L))\n",
      "\n",
      "(8) Project [codegen id : 1]\n",
      "Output [2]: [id#357L, country#358]\n",
      "Input [2]: [id#357L, country#358]\n",
      "\n",
      "(9) BroadcastExchange\n",
      "Input [2]: [id#357L, country#358]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, bigint, true])), [id=#359]\n",
      "\n",
      "(10) BroadcastHashJoin [codegen id : 2]\n",
      "Left keys [1]: [id#337L]\n",
      "Right keys [1]: [id#357L]\n",
      "Join condition: None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.explain(mode=\"formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a63461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
